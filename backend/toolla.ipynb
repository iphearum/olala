{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install ollama chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama, chromadb, pytesseract, datetime, re, json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# import pandas_access as mdb\n",
    "# import pandas as pd\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = chromadb.Client()\n",
    "config = {\n",
    "    **dotenv_values(\".env\"),  # load shared development variables\n",
    "    # **os.environ,  # override loaded values with environment variables\n",
    "}\n",
    "embeded_model = config['embeded_model']\n",
    "chatllm_model = config['chatllm_model']\n",
    "# tools_model = config['tools_model']\n",
    "chatllm_model = 'phi3'\n",
    "tools_model = 'toolla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = open('./datasets/tools.json')\n",
    "func_calls = json.load(tools)\n",
    "func_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tool_prompt = \"\"\"\n",
    "Base on this query \"{question}\".\n",
    "You are a helpful assistant that tells the user which tools to use and which inputs to give to the tools.  The list of descriptions of available tools in JSON format is \n",
    "{tool_list}.  \n",
    "The user will ask a task to be performed and you will respond with the proper tool to use.  If a task requires multiple steps you will return the tool for the first step and the user will respond with an result from the tool used. If no tool is needed, simply answer the question without it and just say the word \"no_tools\". You will return tool to be used only text inside as JSON format with following structure \n",
    "```json\n",
    "{{ \n",
    "    \"tool\": \"<name>\", \n",
    "    \"inputs\": {{ \n",
    "        \"<key>\": \"<value>\"\n",
    "    }} \n",
    "}}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.get_or_create_collection(name='toolla2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each document in a vector embedding database\n",
    "def embedded(doc_splits=[]):\n",
    "    text_representation = []\n",
    "    for data in doc_splits:\n",
    "        text_representation.append(json.dumps(data))\n",
    "    for i, d in enumerate(text_representation):\n",
    "        if type(d) is not str:\n",
    "            d = d.page_content\n",
    "\n",
    "        response = ollama.embeddings(model=tools_model, prompt=d)\n",
    "        embedding = response[\"embedding\"]\n",
    "        collection.upsert(\n",
    "            ids=[str(i)],\n",
    "            embeddings=[embedding],\n",
    "            documents=[d]\n",
    "        )\n",
    "\n",
    "def get_tools(prompt=None):\n",
    "    response = ollama.embeddings(model=tools_model, prompt=prompt)\n",
    "    print(response)\n",
    "    results = collection.query(query_embeddings=[response[\"embedding\"]], n_results=3)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded(doc_splits=func_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Give a list of songs and albums\"\n",
    "res = get_tools(prompt=prompt)\n",
    "# data = json.loads(res['documents'][0][0])\n",
    "chat = ollama.generate(model='llama3.1', prompt=default_tool_prompt.format(tool_list=res['documents'], question=prompt))\n",
    "chat['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = OpenAI(model_name='phi3', openai_api_base=\"http://127.0.0.1:11434/v1\", openai_api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke('Give a list of songs and albums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = collection.query(\n",
    "#     query_texts=[\"set alarm to 12:00:00\"], # Chroma will embed this for you\n",
    "#     n_results=2 # how many results to return\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SearxSearchWrapper\n",
    "from langchain.agents import load_tools\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"searx-search-results-json\"], searx_host=\"http://localhost:8888\", num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search = SearxSearchWrapper(searx_host=\"https://psarai.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.results(\n",
    "    \"Large Language Model prompt\",\n",
    "    num_results=5,\n",
    "    engine=\"google\",\n",
    "    safe_mode=True,\n",
    "    # language=\"English\",\n",
    "    # sort_by=\"relevance\",\n",
    "    # date_range=\"past_year\",\n",
    "    # categories=\"science\",\n",
    "    # time_range=\"year\",\n",
    ")\n",
    "pprint.pp(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.1\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url='http://127.0.0.1:11434'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "In the lush canopy of a tropical rainforest, two mischievous monkeys, Coco and Mango, swung from branch to branch, their playful antics echoing through the trees. They were inseparable companions, sharing everything from juicy fruits to secret hideouts high above the forest floor. One day, while exploring a new part of the forest, Coco stumbled upon a beautiful orchid hidden among the foliage. Entranced by its delicate petals, Coco plucked it and presented it to Mango with a wide grin. Overwhelmed by Coco's gesture of friendship, Mango hugged Coco tightly, cherishing the bond they shared. From that day on, Coco and Mango ventured through the forest together, their friendship growing stronger with each passing adventure. As they watched the sun dip below the horizon, casting a golden glow over the treetops, they knew that no matter what challenges lay ahead, they would always have each other, and their hearts brimmed with joy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "chunks = text_splitter.split_text(text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_texts(chunks, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_retrieval_chain(combine_docs_chain=llm,retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, retrieval_qa_chat_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Tell me name of monkeys and where do they live\"}).tool_calls\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = ChatOpenAI(model=\"phi3\", base_url=\"http://127.0.0.1:11434/v1\", api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='add', description='Adds a and b.', args_schema=<class 'pydantic.main.addSchema'>, func=<function add at 0x70bbf0541990>),\n",
       " StructuredTool(name='multiply', description='Multiplies a and b.', args_schema=<class 'pydantic.main.multiplySchema'>, func=<function multiply at 0x70bbf0541a20>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'add_alarm',\n",
       "   'description': 'Add an alarm to the active timers. Displayed as an alarm for the given time.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'time': {'type': 'string',\n",
       "      'description': \"The exact time when the timer should go off, in the format 'YYYY-MM-DD HH:MM:SS'.\"},\n",
       "     'title': {'type': 'string',\n",
       "      'description': 'Optional title of the timer.'}},\n",
       "    'required': ['time']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'add_countdown',\n",
       "   'description': 'Add a countdown timer to the active timers. Displayed as counting down to zero.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'duration': {'type': 'string',\n",
       "      'description': 'A duration in ISO 8601 format.'},\n",
       "     'title': {'type': 'string',\n",
       "      'description': 'Optional title of the timer.'}},\n",
       "    'required': ['duration']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'delete_timer',\n",
       "   'description': 'Cancel one of the active timers',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'id': {'type': 'string'}},\n",
       "    'required': ['id']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'evaluate_expression',\n",
       "   'description': 'Evaluate a mathematical expression in the mathjs syntax',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'expression': {'type': 'string'}},\n",
       "    'required': ['expression']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_current_weather',\n",
       "   'description': 'Get the current weather in a given location',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'latitude': {'type': 'number'},\n",
       "     'longitude': {'type': 'number'}},\n",
       "    'required': ['latitude', 'longitude']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_weather_forecast',\n",
       "   'description': 'Get the weather forecast for 5 days with data every 3 hours in a given location',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'latitude': {'type': 'number'},\n",
       "     'longitude': {'type': 'number'}},\n",
       "    'required': ['latitude', 'longitude']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_places_info',\n",
       "   'description': 'Get information about nearby places using the Google Places API',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'latitude': {'type': 'number'},\n",
       "     'longitude': {'type': 'number'},\n",
       "     'radius': {'type': 'number',\n",
       "      'description': 'The radius in meters around the given location'},\n",
       "     'query': {'type': 'string',\n",
       "      'description': 'A text query like the name of a nearby place'},\n",
       "     'fields': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'description': \"A list of fields to retrieve for each place. Available fields are 'formattedAddress', 'regularOpeningHours', 'currentOpeningHours', 'types', 'rating' and 'websiteUri'\"},\n",
       "     'maxResults': {'type': 'number'}},\n",
       "    'required': ['latitude', 'longitude', 'query', 'fields']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'play_on_spotify',\n",
       "   'description': 'Start playing tracks, an album, artist or a playlist on Spotify. Calling this function replaces the current playlist!',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'trackIds': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'description': 'Optional. An array of track IDs'},\n",
       "     'contextUri': {'type': 'string',\n",
       "      'description': 'Optional. The Spotify URI of an album, artist, or playlist.'}},\n",
       "    'required': []}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'find_artists_and_play_top_songs_on_spotify',\n",
       "   'description': \"Searches for 'queries' on Spotify and plays top songs of the found artist(s). Calling this function replaces the current playlist! Pass multiple artists to one tool invocation to play a mix of top songs from different artists.\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'queries': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'description': 'One or more queries to find artists by.'}},\n",
       "    'required': ['queries']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'find_on_spotify',\n",
       "   'description': 'Find tracks, artists, albums or playlists on Spotify',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'query': {'type': 'string'},\n",
       "     'types': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'description': \"Types to search across. Valid types are: 'track', 'artist', 'album', 'playlist', 'show', and 'episode'.\"},\n",
       "     'limit': {'type': 'integer',\n",
       "      'description': 'The maximum number of items to return'}},\n",
       "    'required': ['query', 'types']}}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "tools = open('./datasets/tools.json')\n",
    "func_calls = json.load(tools)\n",
    "func_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llms.bind_tools(func_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Give me a song of Justin Bieber\"\n",
    "\n",
    "res = llm_with_tools.invoke(query).tool_calls\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = llm_with_tools | PydanticToolsParser(tools=tools)\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
